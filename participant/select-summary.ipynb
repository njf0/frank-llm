{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "from pathlib import Path\n",
                "\n",
                "import pandas as pd\n",
                "import torch\n",
                "from torch.nn.utils.rnn import pad_sequence\n",
                "from transformers import AutoModelForCausalLM, AutoTokenizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# tokenizer = AutoTokenizer.from_pretrained(\"/nfs/public/hf/models/meta-llama/Meta-Llama-3-8B-Instruct\")\n",
                "# model = AutoModelForCausalLM.from_pretrained(\"/nfs/public/hf/models/meta-llama/Meta-Llama-3-8B-Instruct\",\n",
                "#     # token='hf_xxx'\n",
                "#     device_map=\"auto\",\n",
                "#     trust_remote_code=True,\n",
                "#     torch_dtype=torch.bfloat16,\n",
                "#     local_files_only=True\n",
                "# )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "TEMPLATES = ['A1']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for template in TEMPLATES:\n",
                "    path = Path(f'../resources/data/{template}.json')\n",
                "    if not path.exists():\n",
                "        raise FileNotFoundError(f'The template {template} does not exist.')\n",
                "    with path.open(encoding='utf-8') as f:\n",
                "        data = json.load(f)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "system_content = \"The following text contains a question, followed by a process that was used to solve it. Select the steps in the process that are most relevant for inclusion in a summary of that process. Format your output using a list containing the indices of the selected steps, for example: [1, 2, 4].\"\n",
                "\n",
                "inputs = []\n",
                "for example in data.values():\n",
                "\n",
                "    user_content = \"\"\n",
                "    user_content += f\"Question: {example['question']}. Process: \"\n",
                "    for step in example['explanation']:\n",
                "        user_content += f\"{step['step']}. {step['explanation']}. \"\n",
                "\n",
                "    messages = [\n",
                "        {\n",
                "            \"role\": \"system\",\n",
                "            \"content\": system_content\n",
                "        },\n",
                "        {\n",
                "            \"role\": \"user\",\n",
                "            \"content\": user_content\n",
                "        }\n",
                "    ]\n",
                "\n",
                "    inputs.append(messages)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[{'role': 'system',\n",
                            "  'content': 'The following text contains a question, followed by a process that was used to solve it. Select the steps in the process that are most relevant for inclusion in a summary of that process. Format your output using a list containing the indices of the selected steps, for example: [1, 2, 4].'},\n",
                            " {'role': 'user',\n",
                            "  'content': 'Question: In 2026, what will be the population density of Liechtenstein?. Process: 1. The population density of Liechtenstein in 2026 had to be predicted using historic data. 2. Data was found on the population density of Liechtenstein between 2010 and 2021. 3. A predictive model was created using this data. 4. The answer was estimated using this predictive model. '}]"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "input_messages = [tokenizer.apply_chat_template(i) for i in inputs]\n",
                "input_ids = [tokenizer.encode(i, return_tensors=\"pt\") for i in inputs_messages]\n",
                "input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
                "outputs = model.generate(input_ids)\n",
                "responses = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}