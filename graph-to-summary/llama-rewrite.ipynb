{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/njf/code/frank-llm/.env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"/nfs/public/hf/models/meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"/nfs/public/hf/models/meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "#     # token='hf_xxx'\n",
    "#     device_map=\"auto\",\n",
    "#     trust_remote_code=True,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     local_files_only=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../resources/rewriting/examples.json\")\n",
    "with path.open(encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"'You are a query answering system explaining the reasoning behind the methodology chosen to generate an answer. Summarise the following explanation while using formal language and reducing redundancy. Round population figures two three significant figures - for example, 69112701.18 rounds to 69.1 million, 65343184.0 rounds to 65.3 million.\"\n",
    "\n",
    "inputs = []\n",
    "for example in data[:2]:\n",
    "    for explanation in example['explanation']:\n",
    "        user_content = \"\"\n",
    "        user_content += f\"Question: {example['question']} Explanation: {explanation}.\"\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_content\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_content\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        inputs.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'system',\n",
       "   'content': \"'You are a query answering system explaining the reasoning behind the methodology chosen to generate an answer. Summarise the following explanation while using formal language and reducing redundancy. Round population figures two three significant figures - for example, 69112701.18 rounds to 69.1 million, 65343184.0 rounds to 65.3 million.\"},\n",
       "  {'role': 'user',\n",
       "   'content': 'Question: What will be the population of France in 2026? Explanation: The value of the population of France in 2026 is 69247799. HOW: Generated a regression function from times between 2010 and 2018.The predicted value of the population of France in 2026 is 69247799. Retrieved fact(s) from the World Bank and Wikidata knowledge sources.. WHY: Could not find the population of France in 2026. Attempted to infer the required value in 2026 by finding the population of France at other times between 2010 and 2018..'}],\n",
       " [{'role': 'system',\n",
       "   'content': \"'You are a query answering system explaining the reasoning behind the methodology chosen to generate an answer. Summarise the following explanation while using formal language and reducing redundancy. Round population figures two three significant figures - for example, 69112701.18 rounds to 69.1 million, 65343184.0 rounds to 65.3 million.\"},\n",
       "  {'role': 'user',\n",
       "   'content': 'Question: Country in Africa with the lowest urban population in 2010? Explanation: The entity whose urban population in 2010 has the minimum value of 47880.0 is Seychelles. HOW: Retrieved fact(s) from the World Bank and Wikidata knowl- edge sources. Had to solve the sub-queries before determining the urban popula- tion in 2010..'}],\n",
       " [{'role': 'system',\n",
       "   'content': \"'You are a query answering system explaining the reasoning behind the methodology chosen to generate an answer. Summarise the following explanation while using formal language and reducing redundancy. Round population figures two three significant figures - for example, 69112701.18 rounds to 69.1 million, 65343184.0 rounds to 65.3 million.\"},\n",
       "  {'role': 'user',\n",
       "   'content': 'Question: Country in Africa with the lowest urban population in 2010? Explanation: The entity whose urban population in 2010 has the minimum value of 47880.0 is Seychelles. HOW: The country values found for the sub-query include: Botswana, Algeria, Cameroon, Angola, Benin, Burundi, Cape Verde, etc. Re- trieved fact(s) from the World Bank and Wikidata knowledge sources. Had to solve the sub-queries before determining the urban population in 2010..'}]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_messages = [tokenizer.apply_chat_template(i) for i in inputs]\n",
    "input_ids = [tokenizer.encode(i, return_tensors=\"pt\") for i in inputs_messages]\n",
    "input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "outputs = model.generate(input_ids)\n",
    "responses = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
