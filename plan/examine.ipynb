{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = Path(\"/app/plan/outputs/2024-08-16T14:25:47.390158.csv\")\n",
    "log = Path(\"/app/plan/outputs/log.csv\")\n",
    "\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    # skip first row\n",
    "    f.readline()\n",
    "    reader = csv.reader(f)\n",
    "    row = random.choice(list(reader))\n",
    "\n",
    "with open(log, 'r', encoding='utf-8') as f:\n",
    "    df = pd.read_csv(f, index_col=0)\n",
    "\n",
    "q, a = row[0], row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>examples</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>source</th>\n",
       "      <th>system_content</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-16T14:25:47.390158</th>\n",
       "      <td>-1</td>\n",
       "      <td>google/gemma-7b</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>/app/resources/data/full_study.json</td>\n",
       "      <td>Answer the following question.</td>\n",
       "      <td>Full dataset, fixed output parsing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-16T10:52:46.096659</th>\n",
       "      <td>-1</td>\n",
       "      <td>google/gemma-7b</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>/app/resources/data/full_study.json</td>\n",
       "      <td>Answer the following question.</td>\n",
       "      <td>Full dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-16T10:42:49.015545</th>\n",
       "      <td>-1</td>\n",
       "      <td>microsoft/Phi-3-small-128k-instruct</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>/app/resources/data/full_study.json</td>\n",
       "      <td>Answer the following question.</td>\n",
       "      <td>Full dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-16T10:27:20.736488</th>\n",
       "      <td>-1</td>\n",
       "      <td>microsoft/Phi-3-mini-128k-instruct</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>/app/resources/data/full_study.json</td>\n",
       "      <td>Answer the following question.</td>\n",
       "      <td>Full dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-16T10:12:46.991349</th>\n",
       "      <td>-1</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>/app/resources/data/full_study.json</td>\n",
       "      <td>Answer the following question.</td>\n",
       "      <td>Full dataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            examples                                model  \\\n",
       "2024-08-16T14:25:47.390158        -1                      google/gemma-7b   \n",
       "2024-08-16T10:52:46.096659        -1                      google/gemma-7b   \n",
       "2024-08-16T10:42:49.015545        -1  microsoft/Phi-3-small-128k-instruct   \n",
       "2024-08-16T10:27:20.736488        -1   microsoft/Phi-3-mini-128k-instruct   \n",
       "2024-08-16T10:12:46.991349        -1   mistralai/Mistral-7B-Instruct-v0.3   \n",
       "\n",
       "                            temperature  batch_size  \\\n",
       "2024-08-16T14:25:47.390158          0.2          16   \n",
       "2024-08-16T10:52:46.096659          0.2          16   \n",
       "2024-08-16T10:42:49.015545          0.2          16   \n",
       "2024-08-16T10:27:20.736488          0.2          16   \n",
       "2024-08-16T10:12:46.991349          0.2          16   \n",
       "\n",
       "                                                         source  \\\n",
       "2024-08-16T14:25:47.390158  /app/resources/data/full_study.json   \n",
       "2024-08-16T10:52:46.096659  /app/resources/data/full_study.json   \n",
       "2024-08-16T10:42:49.015545  /app/resources/data/full_study.json   \n",
       "2024-08-16T10:27:20.736488  /app/resources/data/full_study.json   \n",
       "2024-08-16T10:12:46.991349  /app/resources/data/full_study.json   \n",
       "\n",
       "                                            system_content  \\\n",
       "2024-08-16T14:25:47.390158  Answer the following question.   \n",
       "2024-08-16T10:52:46.096659  Answer the following question.   \n",
       "2024-08-16T10:42:49.015545  Answer the following question.   \n",
       "2024-08-16T10:27:20.736488  Answer the following question.   \n",
       "2024-08-16T10:12:46.991349  Answer the following question.   \n",
       "\n",
       "                                                   description  \n",
       "2024-08-16T14:25:47.390158  Full dataset, fixed output parsing  \n",
       "2024-08-16T10:52:46.096659                        Full dataset  \n",
       "2024-08-16T10:42:49.015545                        Full dataset  \n",
       "2024-08-16T10:27:20.736488                        Full dataset  \n",
       "2024-08-16T10:12:46.991349                        Full dataset  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[::-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "examples                                           -1\n",
       "model                                 google/gemma-7b\n",
       "temperature                                       0.2\n",
       "batch_size                                         16\n",
       "source            /app/resources/data/full_study.json\n",
       "system_content         Answer the following question.\n",
       "description        Full dataset, fixed output parsing\n",
       "Name: 2024-08-16T14:25:47.390158, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[file.stem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which country in Latin America and the Caribbean had the lowest life expectancy in 2014?\n",
      "---\n",
      "Answer the following question. Which country in Latin America and the Caribbean had the lowest life expectancy in 2014? miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur miniatur exorbit exorbitantly miniatur miniatur miniatur miniatur exorbitantly miniatur miniatur miniatur exorbitantly miniatur miniatur miniatur exorbitantly miniatur miniatur miniatur exorbitantly miniatur miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur exorbitantly miniatur miniatur exorbitantly miniatur exorbitantly miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur miniatur exorbitantly miniatur exorbitantly miniatur exorbitantly miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur aught miniatur exorbitantly miniatur\n"
     ]
    }
   ],
   "source": [
    "print(q)\n",
    "print('---')\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
